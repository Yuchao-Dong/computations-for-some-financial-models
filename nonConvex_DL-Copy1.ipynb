{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal as normal\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class one_time_net(torch.nn.Module):\n",
    "    def __init__(self,d,acti):\n",
    "        super(one_time_net,self).__init__()\n",
    "        self.n_neuron=[d,d+10,d+10,1]\n",
    "        self.norm=torch.nn.BatchNorm1d(self.n_neuron[0])\n",
    "        self.acti=acti\n",
    "        self.layers=torch.nn.ModuleList([self._one_layer(self.n_neuron[0],self.n_neuron[1],torch.nn.ReLU()),self._one_layer(self.n_neuron[1],self.n_neuron[2],torch.nn.ReLU()),\n",
    "                                        self._one_layer(self.n_neuron[2],self.n_neuron[3],acti)])\n",
    "    def _one_layer(self,input_dim,output_dim,activation_fn=torch.nn.ReLU()):\n",
    "        if activation_fn != None:\n",
    "            return torch.nn.Sequential(torch.nn.Linear(input_dim,output_dim),torch.nn.BatchNorm1d(output_dim),activation_fn)\n",
    "        else:\n",
    "            return torch.nn.Sequential(torch.nn.Linear(input_dim,output_dim),torch.nn.BatchNorm1d(output_dim))\n",
    "    def forward(self,x):\n",
    "        norm=self.norm(x)\n",
    "        l1=self.layers[0](x)\n",
    "        l2=self.layers[1](l1)\n",
    "        out=self.layers[2](l2)\n",
    "        return out       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model parameters\n",
    "r=0.03 #interest rate\n",
    "mu=0.07 #average return\n",
    "sigma=0.3 #volatility\n",
    "#lam=1\n",
    "#jump=-0.1\n",
    "T=1 #terminal time\n",
    "c1=1.2 #terminal utility parameter1\n",
    "c2=0 #terminal utility parameter2\n",
    "xref=0#terminal utility parameter3\n",
    "gamma=0.5 #risk aversion\n",
    "d=0 #lower bound of strategy\n",
    "u=1 #upper bound of strategy\n",
    "zmin=1e-4\n",
    "zmax=2\n",
    "N=10\n",
    "deltat=T/N\n",
    "sqrt=np.sqrt(deltat)\n",
    "eta=mu-r\n",
    "pi0=eta/sigma**2/gamma\n",
    "pistar=d*(pi0<d)+pi0*(pi0>=d)*(pi0<=u)+u*(pi0>u)\n",
    "AA=eta*pistar-gamma/2*pistar**2*sigma**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wealthmodel(object):\n",
    "    def __init__(self,mu,r,sigma,deltat):\n",
    "        self.mu=mu\n",
    "        self.r=r\n",
    "        self.sigma=sigma\n",
    "        self.deltat=deltat\n",
    "        self.sqrt=np.sqrt(deltat)\n",
    "        #self.noise=torch.distributions.normal.Normal(torch.tensor([0.0]),torch.tensor([1.0]))\n",
    "    def sample(self,w,pi,batch_size):\n",
    "        noise=torch.distributions.multivariate_normal.MultivariateNormal(torch.zeros(batch_size),torch.eye(batch_size))\n",
    "        next_w=w*((self.mu-self.r)*self.deltat*pi+self.sigma*pi*self.sqrt*noise.sample().reshape([batch_size,1]))+w\n",
    "        return next_w\n",
    "    def utility(self,w):\n",
    "        return w**(1-gamma)/(1-gamma)*(w<xref).float()+(c1*w**(1-gamma)/(1-gamma)+c2)*(w>=xref).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=512\n",
    "lr=5e-4\n",
    "model=wealthmodel(mu,r,sigma,deltat)\n",
    "N_iter=16000\n",
    "values=[]\n",
    "controls=[]\n",
    "for i in range(N):\n",
    "    values.append(one_time_net(1,None))\n",
    "    controls.append(one_time_net(1,torch.nn.Sigmoid()))\n",
    "voptims=[]\n",
    "coptims=[]\n",
    "for i in range(N):\n",
    "    voptims.append(torch.optim.Adam(values[i].parameters(),lr=lr))\n",
    "    coptims.append(torch.optim.Adam(controls[i].parameters(),lr=lr))\n",
    "criterion=torch.nn.MSELoss()\n",
    "noise=torch.distributions.multivariate_normal.MultivariateNormal(torch.zeros(batch_size),torch.eye(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(controls):\n",
    "    for name,para in i.named_parameters():\n",
    "        if name=='layers.2.1.bias':\n",
    "            torch.nn.init.constant_(para,np.log(pistar/(1-pistar)))\n",
    "        elif 'layers' in name:\n",
    "            #torch.nn.init.constant_(para, 0)\n",
    "            torch.nn.init.normal_(para, std=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N_iter):\n",
    "    w=(zmax-zmin)*torch.rand([batch_size,1])+zmin\n",
    "    pi=(u-d)*controls[-1](w)+d\n",
    "    brown=noise.sample().reshape([batch_size,1])\n",
    "    next_w=w*torch.exp((mu-r)*deltat*pi-0.5*sigma**2*pi**2*deltat+pi*sigma*sqrt*brown)\n",
    "    target=model.utility(next_w)\n",
    "    policy_loss=-1*target.mean()\n",
    "    coptims[-1].zero_grad()\n",
    "    policy_loss.backward()\n",
    "    coptims[-1].step()\n",
    "    v=values[-1](w)\n",
    "    loss=criterion(v,target.detach())\n",
    "    voptims[-1].zero_grad()\n",
    "    loss.backward()\n",
    "    voptims[-1].step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in reversed(range(N-1)):\n",
    "    for i in range(N_iter):\n",
    "        w=(zmax-zmin)*torch.rand([batch_size,1])+zmin\n",
    "        pi=(u-d)*controls[t](w)+d\n",
    "        brown=noise.sample().reshape([batch_size,1])\n",
    "        next_w=w*((mu-r)*deltat*pi+sigma*pi*sqrt*brown)+w\n",
    "        target=values[t+1](next_w)\n",
    "        policy_loss=-1*target.mean()\n",
    "        coptims[t].zero_grad()\n",
    "        policy_loss.backward()\n",
    "        coptims[t].step()\n",
    "        v=values[t](w)\n",
    "        loss=criterion(v,target.detach())\n",
    "        voptims[t].zero_grad()\n",
    "        loss.backward()\n",
    "        voptims[t].step()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=N-1\n",
    "zgrid=np.linspace(zmin,zmax,1001)\n",
    "z=torch.tensor(zgrid).reshape([-1,1]).float()\n",
    "pi=(u-d)*controls[t](z)+d\n",
    "v=values[t](z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(zgrid,pi.detach().numpy().reshape([-1,]))\n",
    "plt.plot(zgrid,pi0*np.ones(shape=zgrid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(zgrid,v.detach().numpy().reshape([-1,]))\n",
    "plt.plot(zgrid,model.utility(z).detach().numpy().reshape([-1,])*np.exp(-1*AA*(T-t*deltat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,p in controls[-1].named_parameters():\n",
    "    print(name,p)\n",
    "    if name=='layers.2.1.bias':\n",
    "        print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888891"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pistar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
