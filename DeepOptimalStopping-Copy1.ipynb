{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=0\n",
    "d=2\n",
    "s_0=100\n",
    "delta=0.05\n",
    "rho=0.6\n",
    "sigma=0.2\n",
    "mean=np.zeros(shape=(d,))\n",
    "cov=np.ones(shape=(d,d))*rho\n",
    "for i in range(d):\n",
    "    cov[i,i]=1\n",
    "F=100\n",
    "B=70\n",
    "K=100\n",
    "c=7/12\n",
    "T=1\n",
    "T_i=1/2\n",
    "N=12\n",
    "N_i=6\n",
    "lr=5e-4\n",
    "delta_t=T/N\n",
    "sqrt_delta_t=np.sqrt(delta_t)\n",
    "batch_size=1024\n",
    "M=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BSmodel(batch_size):\n",
    "    S=np.ones(shape=(batch_size,d,N+1))*s_0\n",
    "    for i in range(0,N):\n",
    "        brown=np.random.multivariate_normal(mean=mean,cov=cov,size=(batch_size,))*sqrt_delta_t\n",
    "        S[:,:,i+1]=S[:,:,i]*np.exp((r-0.5*sigma**2)*delta_t+sigma*brown)\n",
    "    for i in range(N_i,N+1):\n",
    "        S[:,:,i]*=(1-delta)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makesample(S):\n",
    "    bs=S.shape[0]\n",
    "    X=np.zeros(shape=(bs,d+2,N+1))\n",
    "    X[:,:d,:]=S\n",
    "    for i in range(1,N+1):\n",
    "        X[:,d,i]=X[:,d,i-1]+(np.amin(S[:,:,i],axis=1)<B).astype(np.int)\n",
    "    X[:,d,:]=(X[:,d,:]>0).astype(np.int)\n",
    "    X[:,d+1,0]=F\n",
    "    for i in range(1,N+1):\n",
    "        X[:,d+1,i]=np.exp(-1*r*delta_t)*X[:,d+1,i-1]+np.exp(-1*r*delta_t)*c\n",
    "    price=np.amin(S[:,:,N],axis=1)\n",
    "    X[:,d+1,N]+=np.exp(-1*r*T)*(X[:,d,N]==1)*(price<K)*(price-F)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bermudian(x):\n",
    "    return torch.nn.functional.relu(torch.max(x,dim=1)[0]-K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class one_time_net(torch.nn.Module):\n",
    "    def __init__(self,d):\n",
    "        super(one_time_net,self).__init__()\n",
    "        self.n_neuron=[d,d+40,d+40,1]\n",
    "        self.norm=torch.nn.BatchNorm1d(self.n_neuron[0])\n",
    "        #self.layer1=self._one_layer(self.n_neuron[0],self.n_neuron[1],torch.nn.ReLU())\n",
    "        #self.layer2=self._one_layer(self.n_neuron[1],self.n_neuron[2],torch.nn.ReLU())\n",
    "        #self.layer3=self._one_layer(self.n_neuron[2],self.n_neuron[3],None)\n",
    "        self.layers=torch.nn.ModuleList([self._one_layer(self.n_neuron[0],self.n_neuron[1],torch.nn.ReLU()),self._one_layer(self.n_neuron[1],self.n_neuron[2],torch.nn.ReLU()),\n",
    "                                        self._one_layer(self.n_neuron[2],self.n_neuron[3],torch.nn.Sigmoid())])\n",
    "    def _one_layer(self,input_dim,output_dim,activation_fn=torch.nn.ReLU()):\n",
    "        one_layer=torch.nn.Sequential()\n",
    "        one_layer.add_module('Linear',torch.nn.Linear(input_dim,output_dim))\n",
    "        one_layer.add_module('Norm',torch.nn.BatchNorm1d(output_dim))\n",
    "        if activation_fn != None:\n",
    "            one_layer.add_module('activation',activation_fn)\n",
    "        return one_layer\n",
    "    def forward(self,x):\n",
    "        norm=self.norm(x)\n",
    "        l1=self.layers[0](x)\n",
    "        l2=self.layers[1](l1)\n",
    "        out=self.layers[2](l2)\n",
    "        return out      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopping_rule={}\n",
    "for i in range(1,N):\n",
    "    stopping_rule['t{}'.format(i)]=one_time_net(d+2)\n",
    "optimizers={}\n",
    "for i in range(1,N):\n",
    "    optimizers['t{}'.format(i)]=torch.optim.Adam(stopping_rule['t{}'.format(i)].parameters(),lr=lr)\n",
    "Y0=torch.nn.Parameter(torch.tensor(95,dtype=torch.float32))\n",
    "Yoptimizer=torch.optim.Adam(list([Y0]),lr=lr)\n",
    "for i in list(stopping_rule):\n",
    "    for name,para in stopping_rule[i].named_parameters():\n",
    "        if 'Linear' in name and 'weight' in name:\n",
    "            torch.nn.init.xavier_normal_(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 500 loss:14.373245239257812,Y0:95.22394561767578\n",
      "Episode 1000 loss:11.951170921325684,Y0:95.44950103759766\n",
      "Episode 1500 loss:13.368833541870117,Y0:95.6738510131836\n",
      "Episode 2000 loss:8.339753150939941,Y0:95.896484375\n",
      "Episode 2500 loss:7.7689995765686035,Y0:96.11275482177734\n",
      "Episode 3000 loss:8.199078559875488,Y0:96.32814025878906\n",
      "Episode 3500 loss:6.265344619750977,Y0:96.53997802734375\n",
      "Episode 4000 loss:4.849088191986084,Y0:96.75102996826172\n",
      "Episode 4500 loss:4.56123161315918,Y0:96.9554443359375\n",
      "Episode 5000 loss:2.4713234901428223,Y0:97.15675354003906\n",
      "Episode 5500 loss:2.1380627155303955,Y0:97.35161590576172\n",
      "Episode 6000 loss:1.975286602973938,Y0:97.54026794433594\n",
      "Episode 6500 loss:1.4469773769378662,Y0:97.72142791748047\n",
      "Episode 7000 loss:0.576478898525238,Y0:97.89400482177734\n",
      "Episode 7500 loss:1.1899888515472412,Y0:98.0608139038086\n",
      "Episode 8000 loss:0.08156228810548782,Y0:98.21061706542969\n",
      "Episode 8500 loss:0.32949063181877136,Y0:98.3551254272461\n",
      "Episode 9000 loss:0.07652226835489273,Y0:98.4880599975586\n",
      "Episode 9500 loss:0.2822265625,Y0:98.59231567382812\n",
      "Episode 10000 loss:0.30252015590667725,Y0:98.6823959350586\n",
      "Training Finish. Use 713.1874904632568s\n"
     ]
    }
   ],
   "source": [
    "since=time.time()\n",
    "for i in range(M):\n",
    "    S=BSmodel(batch_size)\n",
    "    X=makesample(S)\n",
    "    X=torch.tensor(X,dtype=torch.float32,requires_grad=False)\n",
    "    continue_value=X[:,-1,N]\n",
    "    for k in reversed(range(1,N)):\n",
    "        stopping_value=X[:,-1,k]\n",
    "        f=stopping_rule['t{}'.format(k)](X[:,:,k])\n",
    "        loss=(stopping_value*f.squeeze()+continue_value*(1-f.squeeze())).mean()\n",
    "        optimizer=optimizers['t{}'.format(k)]\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        newF=stopping_rule['t{}'.format(k)](X[:,:,k])\n",
    "        index=(newF>0.5).reshape((-1,))\n",
    "        continue_value[index]=stopping_value[index]\n",
    "    loss=(Y0-continue_value.mean()).pow(2)\n",
    "    if (i+1)%500==0:\n",
    "        print('Episode {} loss:{},Y0:{}'.format(i+1,loss.item(),Y0.item()))\n",
    "        #print(loss.item())\n",
    "        #print(Y0.item())\n",
    "    Yoptimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    Yoptimizer.step()\n",
    "print('Training Finish. Use {}s'.format(time.time()-since))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "S=BSmodel(4096*100)\n",
    "X=makesample(S)\n",
    "X=torch.tensor(X,dtype=torch.float32,requires_grad=False)\n",
    "continue_value=X[:,-1,N]\n",
    "for k in reversed(range(1,N)):\n",
    "    stopping_value=X[:,-1,k]\n",
    "    newF=stopping_rule['t{}'.format(k)](X[:,:,k])\n",
    "    index=(newF>0.5).reshape((-1,))\n",
    "    continue_value[index]=stopping_value[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.8381118774414\n"
     ]
    }
   ],
   "source": [
    "print(continue_value.mean().item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
