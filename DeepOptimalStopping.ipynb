{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=0.05\n",
    "d=2\n",
    "s_0=90\n",
    "delta=0.1\n",
    "sigma=0.2\n",
    "rho=0\n",
    "K=100\n",
    "T=3\n",
    "N=9\n",
    "lr=5e-4\n",
    "delta_t=T/N\n",
    "sqrt_delta_t=np.sqrt(delta_t)\n",
    "batch_size=2048\n",
    "M=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(batch_size):\n",
    "    S=np.ones(shape=(batch_size,d,N+1))*s_0\n",
    "    for i in range(batch_size):\n",
    "        for j in range(N):\n",
    "            brown=np.random.normal(size=(d,))*sqrt_delta_t\n",
    "            S[i,:,j+1]=S[i,:,j]*np.exp((r-delta-0.5*sigma**2)*delta_t+sigma*brown)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_tf(x):\n",
    "    return torch.nn.functional.relu(torch.max(x,dim=1)[0]-K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class one_time_net(torch.nn.Module):\n",
    "    def __init__(self,d):\n",
    "        super(one_time_net,self).__init__()\n",
    "        self.n_neuron=[d,d+40,d+40,1]\n",
    "        self.norm=torch.nn.BatchNorm1d(self.n_neuron[0])\n",
    "        #self.layer1=self._one_layer(self.n_neuron[0],self.n_neuron[1],torch.nn.ReLU())\n",
    "        #self.layer2=self._one_layer(self.n_neuron[1],self.n_neuron[2],torch.nn.ReLU())\n",
    "        #self.layer3=self._one_layer(self.n_neuron[2],self.n_neuron[3],None)\n",
    "        self.layers=torch.nn.ModuleList([self._one_layer(self.n_neuron[0],self.n_neuron[1],torch.nn.ReLU()),self._one_layer(self.n_neuron[1],self.n_neuron[2],torch.nn.ReLU()),\n",
    "                                        self._one_layer(self.n_neuron[2],self.n_neuron[3],torch.nn.Sigmoid())])\n",
    "    def _one_layer(self,input_dim,output_dim,activation_fn=torch.nn.ReLU()):\n",
    "        one_layer=torch.nn.Sequential()\n",
    "        one_layer.add_module('Linear',torch.nn.Linear(input_dim,output_dim))\n",
    "        one_layer.add_module('Norm',torch.nn.BatchNorm1d(output_dim))\n",
    "        if activation_fn != None:\n",
    "            one_layer.add_module('activation',activation_fn)\n",
    "        return one_layer\n",
    "    def forward(self,x):\n",
    "        norm=self.norm(x)\n",
    "        l1=self.layers[0](x)\n",
    "        l2=self.layers[1](l1)\n",
    "        out=self.layers[2](l2)\n",
    "        return out      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopping_rule={}\n",
    "for i in range(1,N):\n",
    "    stopping_rule['t{}'.format(i)]=one_time_net(d+1)\n",
    "optimizers={}\n",
    "for i in range(1,N):\n",
    "    optimizers['t{}'.format(i)]=torch.optim.Adam(stopping_rule['t{}'.format(i)].parameters(),lr=lr)\n",
    "Y0=torch.nn.Parameter(torch.tensor(10,dtype=torch.float32))\n",
    "Yoptimizer=torch.optim.Adam(list([Y0]),lr=lr)\n",
    "for i in list(stopping_rule):\n",
    "    for name,para in stopping_rule[i].named_parameters():\n",
    "        if 'Linear' in name and 'weight' in name:\n",
    "            torch.nn.init.xavier_normal_(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 500 loss:13.911758422851562,Y0:9.782146453857422\n",
      "Episode 1000 loss:7.793548107147217,Y0:9.582137107849121\n",
      "Episode 1500 loss:5.795093059539795,Y0:9.39547061920166\n",
      "Episode 2000 loss:3.217606782913208,Y0:9.218242645263672\n",
      "Episode 2500 loss:2.5977768898010254,Y0:9.049223899841309\n",
      "Episode 3000 loss:1.1588634252548218,Y0:8.887639045715332\n"
     ]
    }
   ],
   "source": [
    "for i in range(M):\n",
    "    S=sample(batch_size)\n",
    "    S=torch.tensor(S,dtype=torch.float32,requires_grad=False)\n",
    "    g=g_tf(S)\n",
    "    S=torch.cat([S,torch.unsqueeze(g,dim=1)],dim=1)\n",
    "    continue_value=S[:,-1,N]*torch.exp(-1*r*torch.tensor(N).double()*delta_t)\n",
    "    for k in reversed(range(1,N)):\n",
    "        stopping_value=S[:,-1,k]*torch.exp(-1*r*torch.tensor(k).double()*delta_t)\n",
    "        F=stopping_rule['t{}'.format(k)](S[:,:,k])\n",
    "        loss=-1*(stopping_value*F.squeeze()+continue_value*(1-F.squeeze())).mean()\n",
    "        optimizer=optimizers['t{}'.format(k)]\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        newF=stopping_rule['t{}'.format(k)](S[:,:,k])\n",
    "        index=(newF>0.5).reshape((-1,))\n",
    "        continue_value[index]=stopping_value[index]\n",
    "    loss=(Y0-continue_value.mean()).pow(2)\n",
    "    if (i+1)%500==0:\n",
    "        print('Episode {} loss:{},Y0:{}'.format(i+1,loss.item(),Y0.item()))\n",
    "        #print(loss.item())\n",
    "        #print(Y0.item())\n",
    "    Yoptimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    Yoptimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "S=sample(4096*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "S=torch.tensor(S,dtype=torch.float32,requires_grad=False)\n",
    "g=g_tf(S)\n",
    "S=torch.cat([S,torch.unsqueeze(g,dim=1)],dim=1)\n",
    "continue_value=S[:,-1,N]*torch.exp(-1*r*torch.tensor(N).double()*delta_t)\n",
    "for k in reversed(range(1,N)):\n",
    "    stopping_value=S[:,-1,k]*torch.exp(-1*r*torch.tensor(k).double()*delta_t)\n",
    "    newF=stopping_rule['t{}'.format(k)](S[:,:,k])\n",
    "    index=(newF>0.5).reshape((-1,))\n",
    "    continue_value[index]=stopping_value[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.718098163604736\n"
     ]
    }
   ],
   "source": [
    "print(continue_value.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
